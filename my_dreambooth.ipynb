{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ba7c49c-67ea-468b-a2a7-cf5114627349",
   "metadata": {},
   "source": [
    "# Login to HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c77b82-413c-4c1a-89aa-3afe8ab9ad6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install huggingface_hub\n",
    "from huggingface_hub import login\n",
    "login(\"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\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fcdcec1-a247-4686-8fd9-8cadbd35503c",
   "metadata": {},
   "source": [
    "# Update tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39af7163-2bb8-4a72-9f06-4ff46441a57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!apt-get update -y\n",
    "!apt-get install g++ -y\n",
    "!apt-get install zip unzip -y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d505c80-cbba-4137-9f95-7558a2b02a09",
   "metadata": {},
   "source": [
    "# Install miniconda and xformers (not needed on SD 2.1 run template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2c5ed1-7432-4886-b044-d91c21daf4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cmds = [\"mkdir -p ~/miniconda3\",\n",
    "#         \"wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -O ~/miniconda3/miniconda.sh\",\n",
    "#         \"bash ~/miniconda3/miniconda.sh -b -u -p ~/miniconda3\",\n",
    "#         \"rm -rf ~/miniconda3/miniconda.sh\",\n",
    "#         \"~/miniconda3/bin/conda init bash\",\n",
    "#         \"~/miniconda3/bin/conda init zsh\"]\n",
    "        \n",
    "# with open('miniconda.sh','w') as dst:\n",
    "#     dst.writelines('\\n'.join(cmds))\n",
    "\n",
    "# import os\n",
    "# import stat\n",
    "# os.chmod(\"miniconda.sh\",stat.S_IXOTH)\n",
    "# os.system('./miniconda.sh')\n",
    "# os.system(\"~/miniconda3/bin/conda install pytorch torchvision torchaudio pytorch-cuda=11.6 -c pytorch -c nvidia -y\")\n",
    "# os.system('~/miniconda3/bin/conda install xformers -c xformers/label/dev')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43a01f1-4607-475e-b6f4-24be4ea179d4",
   "metadata": {
    "tags": []
   },
   "source": [
    "# install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a764a75d-920d-4a4c-97fd-139152e246e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/huggingface/diffusers\n",
    "%pip install -q -U --pre triton\n",
    "%pip install --upgrade git+https://github.com/huggingface/diffusers.git transformers accelerate scipy\n",
    "%pip install ftfy\n",
    "%pip install natsort\n",
    "%pip install albumentations\n",
    "%pip install tensorboard\n",
    "%pip install modelcards\n",
    "%pip install OmegaConf\n",
    "%pip install pytorch_lightning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4cf17fb-1130-4c85-b597-0e918aa1b293",
   "metadata": {},
   "source": [
    "# configure instance and class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2377c07e-117a-45b3-8441-fb761e9bfbd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "INSTANCE_PROMPT = 'sksbbark'\n",
    "INSTANCE = INSTANCE_PROMPT.replace(' ','')\n",
    "INSTANCE_DIR = f'data/{INSTANCE}'\n",
    "CLASS_PROMPT = 'treebark'\n",
    "CLASS = CLASS_PROMPT.replace(' ','')\n",
    "CLASS_DIR = f'data/{CLASS}'\n",
    "\n",
    "#MODEL_NAME = \"stabilityai/stable-diffusion-2-base\"\n",
    "#MODEL_NAME = \"runwayml/stable-diffusion-v1-5\"\n",
    "MODEL_NAME = \"stabilityai/stable-diffusion-2\"\n",
    "\n",
    "OUTPUT_DIR = f\"./stable_diffusion_weights/{INSTANCE}\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "print(f\"[*] Weights will be saved at {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa03138-c454-4e88-8dd3-352811f870b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can also add multiple concepts here. Try tweaking `--max_train_steps` accordingly\n",
    "concepts_list = [\n",
    "    {\n",
    "        \"instance_prompt\":      INSTANCE_PROMPT,\n",
    "        \"instance_data_dir\":    INSTANCE_DIR,\n",
    "        \"class_prompt\":         CLASS_PROMPT,\n",
    "        \"class_data_dir\":       CLASS_DIR\n",
    "    },\n",
    "#     {\n",
    "#         \"instance_prompt\":      \"photo of ukj person\",\n",
    "#         \"class_prompt\":         \"photo of a person\",\n",
    "#         \"instance_data_dir\":    \"/content/data/ukj\",\n",
    "#         \"class_data_dir\":       \"/content/data/person\"\n",
    "#     }\n",
    "]\n",
    "\n",
    "# `class_data_dir` contains regularization images\n",
    "import json\n",
    "import os\n",
    "for c in concepts_list:\n",
    "    os.makedirs(c[\"instance_data_dir\"], exist_ok=True)\n",
    "    try:\n",
    "        os.makedirs(c[\"class_data_dir\"], exist_ok=True)\n",
    "    except:\n",
    "        print(f'No class data directory for: {c[\"INSTANCE\"]}')\n",
    "\n",
    "with open(\"concepts_list.json\", \"w\") as f:\n",
    "    json.dump(concepts_list, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9f0c48-6011-4c1e-ac99-16ae660d037d",
   "metadata": {},
   "source": [
    "# STOP AND UPLOAD YOUR TRAINING IMAGES NOW (/workspace/data/$INSTANCE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eed7b05-682c-4fe4-bfcd-700cb0e22e1b",
   "metadata": {},
   "source": [
    "# Run Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da61c191-253d-4a63-994a-6e1d49e5ccf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!accelerate launch diffusers/examples/dreambooth/train_dreambooth.py \\\n",
    "  --pretrained_model_name_or_path={MODEL_NAME} \\\n",
    "  --pretrained_vae_name_or_path=\"stabilityai/sd-vae-ft-mse\" \\\n",
    "  --with_prior_preservation \\\n",
    "  --output_dir={OUTPUT_DIR} \\\n",
    "  --seed=1337 \\\n",
    "  --resolution=512 \\\n",
    "  --train_batch_size=1 \\\n",
    "  --train_text_encoder \\\n",
    "  --mixed_precision=\"no\" \\\n",
    "  --gradient_accumulation_steps=1 \\\n",
    "  --gradient_checkpointing \\\n",
    "  --use_8bit_adam \\\n",
    "  --learning_rate=2e-6 \\\n",
    "  --lr_scheduler=\"constant\" \\\n",
    "  --lr_warmup_steps=0 \\\n",
    "  --sample_batch_size=4 \\\n",
    "  --max_train_steps=4000 \\\n",
    "  --save_interval=100 \\\n",
    "  --num_class_images=110 \\\n",
    "  --save_sample_prompt=\"photo of sksbbark with visible moss\" \\\n",
    "  --concepts_list=\"concepts_list.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9d6e9d-38a3-4ab3-9a07-9c3746fb3404",
   "metadata": {},
   "source": [
    "# Show sample images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ea0c08-7d97-480c-81f8-55d67ca41ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from natsort import natsorted\n",
    "from glob import glob\n",
    "import os\n",
    "WEIGHTS_DIR = natsorted(glob(OUTPUT_DIR + os.sep + \"*\"))[-1]\n",
    "print(f\"[*] WEIGHTS_DIR={WEIGHTS_DIR}\")\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "weights_folder = OUTPUT_DIR\n",
    "folders = sorted([f for f in os.listdir(weights_folder) if f != \"0\"], key=lambda x: int(x))\n",
    "\n",
    "row = len(folders)\n",
    "col = len(os.listdir(os.path.join(weights_folder, folders[0], \"samples\")))\n",
    "scale = 4\n",
    "fig, axes = plt.subplots(row, col, figsize=(col*scale, row*scale), gridspec_kw={'hspace': 0, 'wspace': 0})\n",
    "\n",
    "for i, folder in enumerate(folders):\n",
    "    folder_path = os.path.join(weights_folder, folder)\n",
    "    image_folder = os.path.join(folder_path, \"samples\")\n",
    "    images = [f for f in os.listdir(image_folder) if not os.path.isdir(f)]\n",
    "    for j, image in enumerate(images):\n",
    "        if row == 1:\n",
    "            currAxes = axes[j]\n",
    "        else:\n",
    "            currAxes = axes[i, j]\n",
    "        if i == 0:\n",
    "            currAxes.set_title(f\"Image {j}\")\n",
    "        if j == 0:\n",
    "            currAxes.text(-0.1, 0.5, folder, rotation=0, va='center', ha='center', transform=currAxes.transAxes)\n",
    "        image_path = os.path.join(image_folder, image)\n",
    "        img = mpimg.imread(image_path)\n",
    "        currAxes.imshow(img, cmap='gray')\n",
    "        currAxes.axis('off')\n",
    "        \n",
    "plt.tight_layout()\n",
    "plt.savefig('grid.png', dpi=72)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77efc506-8cbd-4c79-b679-fb213e224b7b",
   "metadata": {},
   "source": [
    "# Convert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d8dea9-f9d8-4124-af06-2c3d3eba6d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_path = WEIGHTS_DIR + \"/model.ckpt\"\n",
    "\n",
    "half_arg = \"\"\n",
    "fp16 = True\n",
    "if fp16:\n",
    "    half_arg = \"--half\"\n",
    "!python diffusers/scripts/convert_diffusers_to_original_stable_diffusion.py --model_path {WEIGHTS_DIR}  --checkpoint_path {ckpt_path} {half_arg}\n",
    "print(f\"[*] Converted ckpt saved at {ckpt_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
